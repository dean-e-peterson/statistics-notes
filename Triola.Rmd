---
title: "Triola"
output: html_document
---

Notes from working through *Essentials of Statistics, 6th Ed.*, by Mario F. Triola

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment = NA)
```

## Chapter 4 - Probability

### Chapter 4-2 - Addition Rule and Multiplication Rule

1. $P(A)$ is the probability that a randomly selected adult has blue eyes
   $P(\bar A)$ is the probability that a randomly selected adult does not have blue eyes.
   
3. They are dependent, but can be considered independent for the purposes of calculations because the sample is (well) under 5% of the population.

5. 74%

7. $P(\bar N) = .670$, and represents surveyed adultswho do travel on commercial flights.

9. 67.6%
```{r}
1 - ((329 + 33) / (329 + 264 + 249 + 145 + 33 + 54 + 31 + 13))
```

11. 906. No, they are not disjoint.
```{r}
qsr <- matrix(c(329, 33, 264, 54, 249, 31, 145, 13), nrow = 2)
rownames(qsr) <- c("Order Accurate", "Order Inaccurate")
colnames(qsr) <- c("McDonald's", "Burger King", "Wendy's", "Taco Bell")
qsr
(sum(qsr[1,]) + sum(qsr[,1]) - qsr[1,1]) / sum(qsr)
```

13. a) Yes, the events are independent, and the probability is .01997
    b) No, the events are dependent, and the probability is 0.01986 

```{r}
(sum(qsr[, "Taco Bell"]) / sum(qsr))^2
sum(qsr[, "Taco Bell"]) / sum(qsr) * (sum(qsr[, "Taco Bell"]) - 1) / (sum(qsr) - 1)
```

15. a) Yes, the events are independent, and the probability is .7794
    b) No, the events are dependent, and the probability is .7793
```{r}
(sum(qsr["Order Accurate",]) / sum(qsr))^2
sum(qsr["Order Accurate",]) / sum(qsr) * (sum(qsr["Order Accurate",]) - 1) / (sum(qsr) - 1)
```

19. .0156

```{r}
sum(qsr[,"Wendy's"]) / sum(qsr) * (sum(qsr[,"Wendy's"])-1) / (sum(qsr) - 1) * (sum(qsr[,"Wendy's"])-2) / (sum(qsr) - 2) 

(factorial(sum(qsr[,"Wendy's"])) / factorial(sum(qsr[,"Wendy's"]) - 3)) / (factorial(sum(qsr)) / factorial(sum(qsr) - 3))

```

### 4.3 Complements, Conditional Probability, and Bayes' Theorem

5. Probability of 3 boys = $\frac12^3 = \frac18$.  Probability of the complement, at least one girl, = $\frac78$, or .875

7. .982

```{r}
1 - .512^6
```

9. .344

```{r}
1 - .9^4
```

11. .965

```{r}
1 - .8^15
```

13. a. .628
    b. .372
    c. That if you give someone the right denomination to purchase something, they are more likely to do so compared to breaking a higher denomination.
```{r}
27 / (27 + 16)
16 / (27 + 16)
```

17. .00173

```{r}
2/1155
335/337
```

19. .994

21. a. .9991
    b. .999973

```{r}
1 - .03^2
1 - .03^3
```

23. .490

```{r}
1 - (1-.126)^5
```

25. Birthday, 25 people, .569

```{r}
1 - prod((365 - 0:24) / 365)
```

### 4.4 Counting

3. Permutations rule with repeated values?, because order matters
   NOPE: Multiplication rule.
   
5. 1/10000, or .0001

7. 684, nope 1/171

```{r}
factorial(19) / (factorial(17) * factorial(2))
```

9. 1/40320, or .0000248

```{r}
1 / factorial(8)
```

11. 1/254251200

```{r}
factorial(50) / factorial(50 - 5)
```

13. 1/100,000,000.  No

```{r}
100^4
```

15. 1/1820

```{r}
choose(16,4)
factorial(16) / (factorial(16-4) * factorial(4))
```

17. 1/292,201,338

```{r}
choose(69, 5) * 26
```

19. 1/100,000

21. 800, 6,400,000,000

```{r}
800 * 800 * 10000
```

23. a. 5040
    b. 210
    c. 1/5040, nope 1/210

```{r}
factorial(10)/factorial(10-4)
factorial(10)/(factorial(10-4)*factorial(4))
```

25. 40,320, 1/40,320

```{r}
factorial(8)
```

27. 20,922,790,000,000, no 653,837,184,000, forgot repeat letters.


```{r}
factorial(16) / (2*2*2*2*2)
```

31. 62

```{r}
2^5 + 2^4 + 2^3 + 2^2 + 2^1
```

33. 4.7%.  Nope, 4.8% 

```{r}
(4/52) * (16/51) * 2
```

35. 

## 5. Discrete Probability Distributions

### 5.1 Probability Distributions

1. The number of girls born, integers 0 through 4 inclusive, and yes, its values are numerical.

3. Yes, not counting rounding errors, they sum to 1.  It is a probability distribution because additionally all values are between 0 and 1 inclusive.

5. a. Continuous random variable
   b. Not a random variable
   c. Discrete random variable
   d. Continuous random variable
   e. Discrete random variable?  (Assuming you consider shoe sizes numerical, not categorical)

7. Yes, it's a probability distribution.  Mean = 2.5, sd = 1.246, nope, 1.1

9. No, it's not a probability distribution because the probabilities don't sum to 1.

11. Yes, it's a probability distribution.  Mean = 1.648 (1.6). sd=.744, nope .862 (.9)

13. No, because there is no numerical random variable.

15. Mean = 4.0 (3.996), Sd=1.4 (1.418)

```{r}
births <- 0:8
prob <- c(.004, .031, .109, .219, .273, .219, .109, .031, .004)
births
sum(prob)
girls <- data.frame(births, prob)
mu = sum(girls$births * girls$prob)
sd = (sum(girls$births^2 * girls$prob) - mu^2) ^ .5
mu
sd
```

17. No

19. a. .109
    b. .144
    c. part b
    d. No, because the probability of that many or more girls is .144, which is greater than .05.
    
```{r}
sum(girls$prob[girls$births >= 6])
```

21. Mean = 1.5 (1.48), sd = 1.0 (1.019)

```{r}
sleep <- data.frame(x=0:5, p=c(.172, .363, .306, .129, .027, .002))
mean = sum(sleep$x * sleep$p)
mean
sd = sum((sleep$x - mean)^2 * sleep$p)^.5
sd
mean + 2*sd
sum(sleep$p[sleep$x <= 1])
```

23. No

25. a. .363
    b. .535
    c. part b
    d. No, because the probability of a result that or more extreme is (much) greater than .05.

27. a. 1000
    b. 1/1000
    c. $499
    d. .5
    e. Neither

```{r}
-1 * .999 + 499 * .001
```
    
29. a. -$161 vs $99839
    b. -$21
    c. Yes, because on average the consumer loses money.

```{r}
100000 - 161
-161 * .9986 + (100000-161) * (1-.9986)
```

### 5.2 Binomial Probability Distributions

1. It does not account for the possibility that the two customers that want drone deliveries could appear in any order withing the five people being considered.  Therefore, it underestimates the probability.

3. No, they are dependent.  They can be treated as independent, though, because 30 out of 1009 is less than 5% for a sample size.  No, the probability cannot be found directly with the binomial probability formula, because that formula gives probablities for exactly x successes, not "at least" x successes.  NOPE, yes, you can use the formula, but must use it multiple times, basically for the reasons I stated.

5. No, because the observed variable is not in the form of a simple success or failure.

7. Yes, it's binomial.

9. No, because without replacement, the events are not independent, and since the sample is larger than 5%, the events cannot be treated as independent.

11. Yes, it's binomial.

13. a. $\frac45 \cdot \frac45 \cdot \frac15 = \frac{16}{125}$
    b. WWC, WCW, CWW, each with probability $\frac{16}{125}$
    c. $\frac{48}{125}$
    
```{r}
16/125
48/125
```

$$P(x) = {n \choose x}p^x(1-p)^{n-x} = \frac{n!}{(n-x)!x!}p^x(1-p)^{n-x}$$

15. .000002048 Nope, .0000819

```{r}
n <- 8
x <- 7
p <- .2
(factorial(n)/(factorial(n-x)*factorial(x))) * p^x * (1-p)^(n-x)
```

17. .797
```{r}
pbinom(2, size=8, prob=.2)
p <- .2
n <- 8
x <- 0
a0 <- (factorial(n)/(factorial(n-x)*factorial(x))) * p^x * (1-p)^(n-x)
x <- 1
a1 <- (factorial(n)/(factorial(n-x)*factorial(x))) * p^x * (1-p)^(n-x)
x <- 2
a2 <- (factorial(n)/(factorial(n-x)*factorial(x))) * p^x * (1-p)^(n-x)
a0 + a1 + a2
```

19. .168
```{r}
a0
```

21. .147

```{r}
n <- 8
x <- 6
p <- .54
factorial(n)/(factorial(n-x)*factorial(x))
choose(n, x) * p^x * (1-p)^(n-x)
```

23. .089

```{r}
1 - pbinom(7, size=10, prob=.54)
```

25. .00000451

```{r}
x <- 90
n <- 7
p <- .27
choose(x, n) * p^n * (1-p)^(x-n)
pbinom(7, size=90, prob=.27)
```

27. a. .00154
    b. .000064
    c. .0016
    d. Yes, its probability is less than .05

```{r}
factorial(6) / (factorial(1) * factorial(5)) * .2^5 * .8^1
factorial(6) / (factorial(0) * factorial(6)) * .2^6
.001536 + .000064
1  - pbinom(4, size=6, prob=.2)
```

29. a. mean=18, sd=3
    b. 12 and 24
    c. No, it is significantly low, and suggests the treatment had the opposite effect.  NOPE, yes.

```{r}
xsort.var <- 36 * .5 * .5
xsort.var^.5
```

31. a. mean = 7.5, sd = 1.9 NOPE, sd is 1.4
    b. 3.8 and 11.3 NOPE, 4.8 and 10.2
    c. No, 9 is not significantly high because it is within 2 sd of the mean.

```{r}
n <- 10
p <- .75
n*p
(n*p*(1-p))^.5
n*p - 2*(n*p*(1-p))^.5
n*p + 2*(n*p*(1-p))^.5
```

33. .304. No.

```{r}
p <- .01
n <- 36
1 - (1-p)^36
1 - pbinom(0, size=n, prob=p)
1 - (factorial(36)/(factorial(36) * factorial(0)) * .01^0 * .99^36)


```

35. .338, many will be rejected.  NOPE, .662

```{r}
n <- 40
p <- .03
x = 1
1 - pbinom(x, size=n, prob=p)
```

37. a. 8.7 and 23.3.  No
    b. .0736
    c. .242
    d. part c, No, because the probability is greater than .05
    e. No reason to doubt.

```{r}
p <- .16
n <- 100
mm.mean <- n * p
mm.sd <- (n * p * (1-p))^.5
mm.mean + 2*mm.sd
mm.mean - 2*mm.sd
dbinom(19, size=n, prob=p)
1 - pbinom(18, size=n, prob=p)
```

39. a. Yes
    b. .0000369
    c. .0000987, NOPE .000136
    d. part c, yes
    e. They appear to be inaccurate.

```{r}
n <- 611
p <- .43
pres.mean <- n * p
pres.mean
pres.sd <- (n * p * (1-p))^.5
pres.mean - 2*pres.sd
pres.mean + 2*pres.sd
x <- 308
choose(n, x) * p^x * (1-p)^(n-x)
1 - pbinom(x - 1, size=n, prob=.43)
```

41. .0468

```{r}
(1-.06)^4 * .06
```

43.

```{r}

```

### 5.3 Poisson Probability Distributions

1. $\mu=\frac{535}{576} = .929$,
   $x = 2$,
   $e = 2.718$
   
   mu is the average number of buzz bombs per region
   x is the number of buzz bombs hitting a region that we are looking for the probability of.
   e is Euler's constant, deal with it.

```{r}
mu <- 535/576
x <- 2
e <- exp(1)
mu
x
e
```

3. x is a discrete random variable whic can take on integer values from 0 to infinity.  x=2.3 is not possible.

5. a. .158
   b. 8.682
   c. Compares well.  Yes.

```{r}
6.1^5 * exp(-6.1) / factorial(5)
55 * (6.1^5 * exp(-6.1) / factorial(5))
```

7. a. .140
   b. 7.7
   c. Compares well. Yes.

```{r}
6.1^7 * exp(-6.1) / factorial(7)
55 * (6.1^7 * exp(-6.1) / factorial(7))
```

9. .0643

```{r}
mu <- 4221 / 365
mu
x <- 15
mu^x * exp(-mu) / factorial(x)
```

11. I don't think half-life is Poisson, but...
    a. 62.2
    b. .0155

```{r}
mu <- 22713/365
mu
mu^50 * exp(-mu) / factorial(50)
```

13. a. .170
    b. 98.1
    c. Pretty close

```{r}
mu <- 535 / 576
mu
mu^2 * exp(-mu) / factorial(2)
576 * mu^2 * exp(-mu) / factorial(2)
```

15. .9999877

```{r}
(mu <- 33561 / 2969)
1 - (mu^0 * exp(-mu) / factorial(0))
```

17. .0000180  NOPE .0000178, rounding?

```{r}
n <- 5200
(p <- 1/292201338)
(mu <- n * p)
x <- 0

1 - (mu^x * exp(-mu) / factorial(x))
```

## 6. Normal Probability Distributions

### 6.1 The Standard Normal Distribution

1. That's not what normal distribution means.  Those numbers are more likely in a uniform distribution.

3. mean of zero, standard deviation of 1

5. .4

7. .2

9. .6700

11. .6993

13. 1.23

15. -1.45

17. .1093

19. .8997

21. .4013

23. .9772

25. .0214

27. .0174

29. .9545

31. .8413

33. .9999973

35. .5000

37. 2.33

```{r}
qnorm(.99)
```

39. -2.05 and 2.05

```{r}
qnorm(.02)
qnorm(1 - .02)
```

41. .8159 NOPE 1.28

```{r}
qnorm(1-.1)
qnorm(1 - .04)
```

43. .8315 NOPE 1.75

45. 68.3%

```{r}
pnorm(1) - pnorm(-1)
```

47. 99.73%
```{r}
pnorm(3) - pnorm(-3)
```

49. a. 2.275%
    b. 2.275%
    c. 95.45%
    

```{r}
1 - pnorm(2)
pnorm(-2)
pnorm(2) - pnorm(-2)
```

### 6.2 Real Applications of Normal Distributions

1. a. mean 0, sd 1
   b. unitless
   
3. A standard normal distribution has a mean of 0 and a standard deviation of 1.  Any other values for mean and standard deviation make a non-standard normal distribution.

5. .8849

7. .9053

9. 135.998

11. 69.26

13. .0115

15. .6612

17. 24.91

19. 20.9 to 26.1 inches.  No

21. a. 72.11%, too short.
    b. 58.25" to 69.15"
    
23. a. .92%, which suggests that most Mickey Mouses are women.
    b. 64.0 - 68.6 inches.

```{r}
m.mean <- 68.6
m.sd <- 2.8
pnorm((62 - m.mean) / m.sd) - pnorm((56 - m.mean) / m.sd)
```
```{r}
qnorm(1 - .5) * m.sd + m.mean
qnorm(.05) * m.sd + m.mean

```

25. .201, no

```{r}
1 - pnorm((230 - 184) / 55)

```


35. a. mean=75, sd=12
    b. No?
    c. 66 to 75
    d. ?

### 6.3 Sampling Distributions and Estimators 

1. a. They will be .512, they will target the population mean
   b. It will be a normal distribution (APPROXIMATELY)

3. Unbiased estimators: sample mean, sample proportion, sample variance.

5. No, because it is an estimator of a more specific population, that of boys born in China.

7. a. Population variance $\sigma^2=4.667$
   c. Mean of sampling distribution of sample variances $s^2=4.667$
   d. Yes, the sample variance is an unbiased estimator of the population variance, because the mean of the sample variance converges on the population variance as you construct the entire sampling distribution.

```{r}
kids <- c(4,5,9)
kids.mu <- sum(kids) / length(kids)
kids.popvar <- sum((kids - kids.mu)^2) / length(kids)
kids.popvar

samp <- data.frame(a = c(4,4,4,5,5,5,9,9,9), 
                   b = c(4,5,9,4,5,9,4,5,9))
samp$mean <- (samp$a + samp$b) / 2
samp$var <- ((samp$a - samp$mean)^2 + (samp$b - samp$mean)^2) / 1
samp
sum(samp$var) / length(samp$var)
```

9. a. 5
   c. 6
   d. No, it's biased

```{r}
median(kids)
# Only two values in each sample, so
samp$median <- samp$mean
samp$median
sum(samp$median) / length(samp$median)
```

### 6.4 The Central Limit Theorem

1. If they know that the original population of grade-point averages has a normal distribution, or if the sample size that she took is greater than 30.

3. $\mu_\bar x$ is the mean of the sampling distribution means.
   $\sigma_\bar x$ is the standard deviation of the sampling distribution means.

```{r}
pnorm(80, mean=74, sd=12.5)
pnorm(80, mean=74, sd=12.5/(16^.5))
```

5. a. .6844
   b. .9726
   c. Because we assumed that the original population of females that the sample was drawn from had pulse rates that are normally distributed.
   
```{r}
pnorm(76, mean=74.0, sd=12.5) - pnorm(72, mean=74.0, sd=12.5)
pnorm(76, mean=74.0, sd=12.5/2) - pnorm(72, mean=74.0, sd=12.5/2)
```

7. a. 0.1271
   b. 0.2510
   c. ditto 5c.
   
```{r}
1 - pnorm(185, mean=189, sd=39/(27^.5))
```
   
9. .2970, NOPE, .7030, Not if 27 adult males really fit in that elevator.

```{r}
qnorm((1-.02), mean=100, sd=15)
1 - pnorm(131, mean=100, sd=15/2)
```

11. a. 130.8
    b. .00001788
    c. No.
    
```{r}
3500/25
pnorm(140, mean=189, sd=39/5)
1 - pnorm(140, mean=189, sd=39/5)
1 - pnorm(175, mean=189, sd=39/(20^.5))
```

13. a. 140 pounds
    b. 1 (.9999999998..., etc)
    c. .9458
    d. No.
    
```{r}
1 - pnorm(17, mean=14.4, sd=1)
1 - pnorm(17, mean=14.4, sd=1/(122^.5))
```

15. a. .004661
    b. 0
    c. part a

```{r}
pnorm(211, mean=171, sd=46) - pnorm(140, mean=171, sd=46)
pnorm(211, mean=171, sd=46/5) - pnorm(140, mean=171, sd=46/5)
```

17. a. .5575
    b. .9996
    c. part a.  You only eject 1 person at a time.

```{r}
pnorm(72, mean=68.6, sd=2.8)
pnorm(72, mean=68.6, sd=2.8/10)
```
    
19. a. .8877
    b. 1.
    c. part a
    d. Because they are on average shorter than men?

```{r}
x <- (16/(50^.5)) * (275-50)^.5/(275-1)^.5
x
pnorm(105, mean=95.5, sd=x) - pnorm(95, mean=95.5, sd=x)
```

    
21. a. Yes, because the sample size is greater than 5% of the population.  The correct $\sigma_\bar x$ is 2.0505
    b. 0.5963
    
### 6.5 Assessing Normality

1. The histogram should have a symmetric bell shape.  The normal quantile plot would have the points close to a straight line, with no additional pattern.

3. The original population would have to be normally distributed.  You could use a histogram, look for outliers, and use a normal quantile plot.

5. Yes, normal

7. Non-normal.  There is a pattern in addition to a straight line.

9. Normal?
```{r}
cookies <- read.table("data\\Triola\\28 - Chocolate Chip Cookies.txt", header=T, sep="\t")
par(mfrow=c(1,2))
hist(cookies$CHIPS.AHOY.RED.FAT)
qqnorm(cookies$CHIPS.AHOY.RED.FAT)

```

11. Non-normal

```{r}
garbage <- read.table("data/Triola/31 - Garbage Weight.txt", header=T, sep="\t")
garbage$YARD
par(mfrow=c(1,2))
hist(garbage$YARD)
qqnorm(garbage$YARD, datax = T)
```

13. Normal

```{r}
par(mfcol=c(1,2))
hist(cookies$CHIPS.AHOY.RED.FAT)
qqnorm(cookies$CHIPS.AHOY.RED.FAT, datax=TRUE)
```

15. Non-normal

17. 40.7 44.3 34.2 32.5 38.5  Sample to make a graph manually from

19. 1027, 1029, 1034, 1070, 1079, 1079, 963, 1439

21. a. Adding leaves heights normally distributed.
    b. Multiplying leaves heights normally distributed.
    c. Logarithms of heights look slightly different, but still normally distributed.  NOPE, supposed to say NO.
    

```{r}
body <- read.table("data/Triola/01 - Body Data.txt", header=T, sep="\t")
height <- body[body[,2] == 1,]$HEIGHT
par(mfrow=c(1,2))
hist(height)
qqnorm(height, datax=T)

hist(height + 5)
qqnorm(height + 5, datax=T)

hist(height/2.5)
qqnorm(height/2.5, datax=T)

hist(log(height))
qqnorm(log(height), datax=T)

hist(log10(height))
qqnorm(log10(height), datax=T)
```

### 6.6 Normal as Approximation to Binomial

1. a. <= 502.5
   b. 501.5 <= p <= 502.5
   c. >= 502.5

3. p=.2, q=.8, $\mu=20$, $\sigma=4$,
   $\mu$ measures the mean, the expected, number of correct answers.
   $\sigma$ measures the variation in the number of correct answers.

```{r}
(.2 * .8 * 100)^.5
```

5. np and nq are big enough.
   .1102

```{r}
pnorm(7.5, mean=20*.512, sd=(20*.512*(1-.512))^.5)
pbinom(7, size=20, prob=.512)
```

7. np is < 5, so a normal approximation should not be used.

```{r}
20 * .2
```

9. .2028

```{r}
pnorm(19.5, mean=100*.23, sd=(100*.23*(1-.23))^.5)
pbinom(19, size=100, prob=.23)
```

11. .05487, because it is the probability for that exact number of cars, not that number or higher.

```{r}
mu <- 100 * .10
sigma <- (100 * .10 * .9)^.5
pnorm(14.5, mean=mu, sd=sigma) - pnorm(13.5, mean=mu, sd=sigma)
dbinom(14, size=100, prob=.10)
```

13. a. .02117
    b. .2012, no, it's not less than 5%

```{r}
mu <- 879 * .25
sigma <- sqrt(879 * .25 * .75)
pnorm(231.5, mean=mu, sd=sigma) - pnorm(230.5, mean=mu, sd=sigma)
dbinom(231, size=879, prob=.25)
1 - pnorm(230.5, mean=mu, sd=sigma)
1 - pbinom(230, size=879, prob=.25)
```

15. a. .01138
    b. Yes, it is significantly low.

```{r}
n <- 250
p <- .51
pnorm(109.5, mean=n*p, sd=sqrt(n*p*(1-p)))
pbinom(109, size=n, prob=p)
```


21. ?, .170, .172

```{r}
n <- 11
p <- .512
mu <- n * p
sigma <- sqrt(n * p * (1-p))
pnorm(7.5, mean=mu, sd=sigma) - pnorm(6.5, mean=mu, sd=sigma)
dbinom(7, size=n, prob=p)
```

